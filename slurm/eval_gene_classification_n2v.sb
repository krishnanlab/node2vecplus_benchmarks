#!/bin/bash --login

#SBATCH -t 3:55:00
#SBATCH -N 1
#SBATCH -c 4
#SBATCH --mem=16GB
#SBATCH --array=0-242  # 3 networks, 9 x 9 pq settings
#SBATCH -o ../slurm_history/slurm-%A-%a.out

cd $SLURM_SUBMIT_DIR

networks=(STRING HumanBase-global HumanBaseTop-global)
gene_universes=(STRING HBGTX HBGTX)
pqs=(0.01 0.05 0.1 0.5 1 5 10 50 100)

ID=$SLURM_ARRAY_TASK_ID
network=${networks[$(expr $ID % 3)]}
gene_universe=${gene_universes[$(expr $ID % 3)]}
p=${pqs[$(expr $ID / 3 % 9)]}
q=${pqs[$(expr $ID / 3 / 9)]}

if [ $ID == 0 ]; then 
    # submit job for combining all results after all evaluation jobs are finished
    sbatch --dependency=afterany:$SLURM_ARRAY_JOB_ID combine_results.sb gene_classification_n2v
fi

cd ../script
conda activate node2vecplus-bench
time python eval_gene_classification_n2v.py --gene_universe $gene_universe --network $network --p $p --q $q
